{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6caadc0e-e8bb-494e-bf2a-690993bb75e0",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "My goal is to train a model that can recognize Bopomofo characters\n",
    "\n",
    "#### First attempt with limited training set\n",
    "I created this training set by taking screenshots and taking pictures, the characters were all written in the same order. I then split the big image into squares, each with one character inside.\n",
    "\n",
    "And because the screenshot was not always precise, the split image result was often off-center in a certain way.\n",
    "\n",
    "I tested the model (\"session_id\": 32, \"timestamp\": \"2024-12-12T00:14:09\") with various datasets.\n",
    "I found that the model performed better on computer fonts than on handwritten characters. But if I only put my handwritten character in, it gets around the same accuracy as on computer font, which is about 84%. \n",
    "\n",
    "For the prediction mentioned above, my characters are in a very different order than in the training set for the model. \n",
    "\n",
    "Further experiments showed that when the testing set has the same character order as the training set, the accuracy is improved by 10%. Handwriting characters by the same person(Jacob) changed from 65% accuracy to 74% accuracy. A computer font (17 ToneOZ-Zhuyin-Tsuipita-TC) changed from 85% to 95% accuracy.\n",
    "\n",
    "I think the model might have memorized the position of the character in the picture instead of just the shape of the character. \n",
    "\n",
    "#### Second attempt\n",
    "I used various methods to create randomly off-center images as well as changing the contrast, slanting the image and making it burrly. The result is I have at least 2 times more training data than the first attempt. This greatly improves the model's performance and generalization.\n",
    "\n",
    "I found that I can generate each character in its own image with Python, which is much faster and provides me with more options to adjust the image. \n",
    "\n",
    "To make the training dataset more balanced, and add in the different font weights, I grouped the fonts into four types: even strokes, dynamic strokes, heavily stylized, and handwritten fonts. Then applying more augmentation to reflect how written characters look like.\n",
    "\n",
    "This strategy worked, and not only did the model need much fewer epochs to train (from 200 to 30), but it also had improved performance, depending on the test data, it could have 75-100% accuracy. Even the handwriting often got a 75-85% accuracy. Though more off-centered images still decrease the prediction accuracy, it is now less biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980cc2ea-0b26-488c-9664-67289a1ce79f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
